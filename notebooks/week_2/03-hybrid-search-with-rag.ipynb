{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ffb947",
   "metadata": {},
   "source": [
    "### Hybrid Vector datasource for Advanced Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cfeaf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PayloadSchemaType, PointStruct, SparseVectorParams, Document, Prefetch, FusionQuery\n",
    "from qdrant_client.http.models import models\n",
    "import pandas as pd\n",
    "import openai\n",
    "import fastembed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1836a54b",
   "metadata": {},
   "source": [
    "### create hybrid collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "### create collection\n",
    "collection_name = \"amazon_items-collection-hybrid-02\"\n",
    "\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config = {\n",
    "        \"text-embedding-3-small\": VectorParams(size=1536, distance=Distance.COSINE)\n",
    "    },\n",
    "    sparse_vectors_config = {\n",
    "        \"bm25\": SparseVectorParams(modifier=models.Modifier.IDF)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c44ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client.create_payload_index(\n",
    "    collection_name=\"amazon_items-collection-hybrid-02\",\n",
    "    field_name=\"parent_asin\",\n",
    "    field_schema=PayloadSchemaType.KEYWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b643148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_batch(text_list, model=\"text-embedding-3-small\", batch_size=100):\n",
    "    \"\"\"\n",
    "    Get embeddings for a list of text using a specified model.\n",
    "    \n",
    "    Args:\n",
    "        text_list (list): List of text strings to embed.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(text_list) <= batch_size:\n",
    "        response = openai.embeddings.create(\n",
    "            model=model,\n",
    "            input=text_list\n",
    "        )\n",
    "        return [item.embedding for item in response.data]\n",
    "    \n",
    "    all_embeddings = []\n",
    "    counter = 1\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[i:i+batch_size]\n",
    "        response = openai.embeddings.create(\n",
    "            model=model,\n",
    "            input=batch\n",
    "        )\n",
    "        all_embeddings.extend([item.embedding for item in response.data])\n",
    "        print(f\"Processed {counter * batch_size} out of {len(text_list)}\")\n",
    "        counter += 1\n",
    "    \n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ade6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = pd.read_json(\"../../data/meta_Electronics_2022_onwards_with_ratings_100_sample_1000.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ac2c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items.head()\n",
    "len(df_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f41a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_description_and_title(row):\n",
    "    return f\"{row['title']} {row['description']}\"\n",
    "df_items['description'] = df_items.apply(combine_description_and_title, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2385bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_large_image(row):\n",
    "    return row['images'][0].get(\"large\", \"\")\n",
    "df_items['image'] = df_items.apply(extract_first_large_image, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60ec0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_embed = df_items[['description', 'image', \"rating_number\", \"price\", \"average_rating\", \"parent_asin\"]].to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed067440",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_embed = [item['description'] for item in data_to_embed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc9c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_embeddings_batch(text_to_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220c0a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointsstructs = []\n",
    "i = 1\n",
    "for embedding, data in zip(embeddings, data_to_embed):\n",
    "    pointsstructs.append(\n",
    "        PointStruct(\n",
    "            id=i,\n",
    "            vector= { \n",
    "                     \"text-embedding-3-small\": embedding,\n",
    "                     \"bm25\": Document(text=data[\"description\"], model=\"Qdrant/bm25\")\n",
    "            },\n",
    "            payload=data\n",
    "    ))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e420db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pointsstructs[0].vector.get(\"bm25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebbb3c3",
   "metadata": {},
   "source": [
    "### Load into new hybrid collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade3607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "qdrant_client.upsert(\n",
    "    collection_name=\"amazon_items-collection-hybrid-02\",\n",
    "    points=pointsstructs[0:500],\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6655e791",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client.upsert(\n",
    "    collection_name=\"amazon_items-collection-hybrid-02\",\n",
    "    points=pointsstructs[500:],\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d757f",
   "metadata": {},
   "source": [
    "### Perform hybrid-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "806f7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "import openai\n",
    "import instructor\n",
    "instructor_prompt = instructor.from_openai(openai.OpenAI())\n",
    "\n",
    "def create_embeddings(text, model=\"text-embedding-3-small\"):\n",
    "   \n",
    "    response = openai.embeddings.create(\n",
    "        model=model,\n",
    "        input=text\n",
    "    )\n",
    "        \n",
    "    return response.data[0].embedding\n",
    "\n",
    "def retrieve_embedding_data(qd_client: QdrantClient, query, collection_name, k=5):\n",
    "    querry_embeddings = create_embeddings(query)\n",
    "    response = qd_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        prefetch=[Prefetch(\n",
    "            query=querry_embeddings,\n",
    "            using=\"text-embedding-3-small\",\n",
    "            limit=20),\n",
    "            Prefetch(\n",
    "                query=Document(text=query, model=\"qdrant/bm25\"),\n",
    "                using=\"bm25\",\n",
    "                limit=20)\n",
    "            ],\n",
    "        query=FusionQuery(fusion=\"rrf\"),\n",
    "        limit=k,\n",
    "    )\n",
    "    retrieved_context_ids = []\n",
    "    retrieved_context = []\n",
    "    retrieved_scores = []\n",
    "    retrieved_context_ratings = []\n",
    "    \n",
    "    for point in response.points:\n",
    "        retrieved_context_ids.append(point.payload[\"parent_asin\"])\n",
    "        retrieved_context.append(point.payload[\"description\"])\n",
    "        retrieved_scores.append(point.score)\n",
    "        retrieved_context_ratings.append(point.payload[\"average_rating\"])\n",
    "\n",
    "    # return dictionary of retrieved data\n",
    "    return {\n",
    "        \"context_ids\": retrieved_context_ids,\n",
    "        \"context\": retrieved_context,\n",
    "        \"scores\": retrieved_scores,\n",
    "        \"context_ratings\": retrieved_context_ratings\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c71523ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_ids': ['B0BKPB2YQ9',\n",
       "  'B0CGRSBNY1',\n",
       "  'B0BQZ23TJL',\n",
       "  'B015TPLFFO',\n",
       "  'B09QS7W8G5'],\n",
       " 'context': ['Aceele USB and USB C to Ethernet Adapter, 3.3ft Long Cord,Aluminum 3 Ports USB 3.0 Hub with RJ45 10/100/1000 Gigabit Ethernet Adapter, RJ45+Gigabit LAN Network Adapter with USB C Adapter for Laptop []',\n",
       "  'jumper Laptop, 16 Inch FHD IPS Display (16:10), Intel Celeron Quad Core CPU, 4GB DDR4 128GB Storage, Windows 11 Laptops Computer with Office 365 1-Year Subscription, Numeric Keypad, 4 Stereo Speakers. []',\n",
       "  \"EVGA Supernova 1000 G7, 80 Plus Gold 1000W, Fully Modular, Eco Mode with FDB Fan, 10 Year Warranty, Includes Power ON Self Tester, Compact 130mm Size, Power Supply 220-G7-1000-X1 ['EVGA 1000 G7, 80+ GOLD 1000W, 10 Year Warranty, Power Supply 220-G7-1000-X1']\",\n",
       "  '2022 Newest Lenovo IdeaPad 1 Laptop, 14\" Anti-Glare Display, Intel Quad-Core Processor, Intel UHD Graphics, 4GB RAM, 128GB PCIe SSD, Windows 11 + Office 365 1-Year Subscription & Microfiber Cloth []',\n",
       "  'HP 2022 Newest Pavilion 15.6\" FHD 1080P IPS Laptop, 8-Core AMD Ryzen 7-5700U(Up to 4.3GHz, Beat i7-1180G7), 32GB RAM, 1TB NVMe SSD, Numpad, HDMI, WiFi, USB-A&C, Fast Charge, Audio by B&O, Win11 [\\'We sell computers with upgraded configurations. If the computer has modifications (listed above), then the manufacturer box is opened for it to be tested and inspected and to install the upgrades to achieve the specifications as advertised. If no modifications are listed, the item is unopened and untested. Defects & blemishes are significantly reduced by our in-depth inspection & testing. Microprocessor: AMD Ryzen 7 5700U (1.8 GHz base clock, up to 4.3 GHz max boost clock, 8 MB L3 cache, 8 cores, 16 threads) Chipset: AMD Integrated SoC Memory: 32GB DDR4 RAM Video graphics: AMD Radeon Graphics, Integrated Hard drive: 1TB PCIe NVMe M.2 SSD Display: 15.6\" diagonal, FHD (1920 x 1080), IPS, micro-edge, BrightView, 250 nits, 45% NTSC Wireless connectivity: Intel Wi-Fi 6 AX200 (2x2) and Bluetooth 5 combo (Supporting Gigabit data rate) Expansion slots: 1 microSD media card reader; 1 multi-format SD media card reader External ports: 1 SuperSpeed USB Type-C 10Gbps signaling rate (USB Power Delivery, DisplayPort 1.4, HP Sleep and Charge); 2 SuperSpeed USB Type-A 5Gbps signaling rate; 1 HDMI 2.0; 1 AC smart pin; 1 headphone/microphone combo Minimum dimensions (W x D x H): 36.02 x 23.4 x 1.79 cm Weight: 1.75 kg Power supply type: 45 W Smart AC power adapter Battery type: 3-cell, 41 Wh Li-ion Webcam: HP Wide Vision 720p HD camera with integrated dual array digital microphones Audio features: Audio by B&O; Dual speakers; HP Audio Boost Operating system: Windows 11\\']'],\n",
       " 'scores': [0.5, 0.5, 0.33333334, 0.33333334, 0.25],\n",
       " 'context_ratings': [4.2, 4.4, 4.5, 3.5, 4.1]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "sample_query = \"top laptop under 1000$\"\n",
    "retrieved_data = retrieve_embedding_data(qdrant_client, sample_query, \"amazon_items-collection-hybrid-02\", 5)\n",
    "retrieved_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0392b4a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
